import streamlit as st
import weaviate
import weaviate.classes as wvc
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor
import json

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="Hukuk AsistanÄ±", page_icon="âš–ï¸", layout="wide")

# --- CUSTOM CSS (Lacivert & Gray Theme) ---
st.markdown("""
    <style>
        /* Ana arka plan */
        .stApp {
            background-color: #f8f9fa;
        }
        
        /* BaÅŸlÄ±k stili */
        h1 {
            color: #002366; /* Lacivert */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            font-weight: 700;
        }

        /* Chat mesajlarÄ± tasarÄ±mÄ± */
        .stChatMessage {
            border-radius: 15px;
            padding: 10px;
            margin-bottom: 10px;
        }

        /* Sidebar rengi */
        [data-testid="stSidebar"] {
            background-color: #002366;
        }
        [data-testid="stSidebar"] * {
            color: white !important;
        }

        /* Butonlar */
        .stButton>button {
            background-color: #002366;
            color: white;
            border-radius: 5px;
            border: none;
        }
        
        .stButton>button:hover {
            background-color: #4a4a4a; /* Gray on hover */
            color: white;
        }

        /* Expander (Referanslar) */
        .streamlit-expanderHeader {
            background-color: #e9ecef;
            border-radius: 5px;
            color: #002366 !important;
        }
        
        /* Kategori badge */
        .category-badge {
            display: inline-block;
            padding: 5px 12px;
            border-radius: 15px;
            font-size: 12px;
            font-weight: bold;
            margin: 5px 0;
            background-color: #002366;
            color: white;
        }
    </style>
    """, unsafe_allow_html=True)

# --- KATEGORÄ° TANIMLARI ---
COLLECTION_MAP = {
    "kira_hukuku": {
        "collection": "HukukDoc",
        "name": "Kira Hukuku",
        "keywords": ["kira", "kiracÄ±", "kiraya veren", "tahliye", "kira bedeli", "kiralama", "kira sÃ¶zleÅŸmesi", "kira artÄ±ÅŸÄ±", "depozito", "ev sahibi"],
        "emoji": "ğŸ "
    },
    "is_hukuku": {
        "collection": "IsDavalari",
        "name": "Ä°ÅŸ Hukuku",
        "keywords": ["iÅŸÃ§i", "iÅŸveren", "iÅŸ sÃ¶zleÅŸmesi", "iÅŸten Ã§Ä±karma", "kÄ±dem", "fazla mesai", "iÅŸ akdi", "Ã§alÄ±ÅŸan", "istifa", "tazminat", "iÅŸe iade", "patron", "kovdu", "iÅŸsiz"],
        "emoji": "ğŸ’¼"
    }
}

# --- SIDEBAR ---
with st.sidebar:
    st.image("https://img.icons8.com/ios-filled/100/ffffff/scales.png", width=80)
    st.markdown("### Dijital Hukuk Ofisi")
    st.info("Bu asistan, dÃ¶kÃ¼manlarÄ±nÄ±zÄ± tarayarak hukuki gÃ¶rÃ¼ÅŸ oluÅŸturur.")
    
    st.divider()
    
    # Mevcut kategoriler
    st.markdown("#### ğŸ“š Mevcut Kategoriler")
    for key, info in COLLECTION_MAP.items():
        st.markdown(f"{info['emoji']} **{info['name']}**")
    
    st.divider()
    st.caption("Versiyon: 3.0 (Ultra Fast - Single LLM)")

st.title("âš–ï¸ Profesyonel Hukuk DanÄ±ÅŸmanÄ±")

# --- BAÄLANTI ---
W_URL = st.secrets["WEAVIATE_URL"]
W_API = st.secrets["WEAVIATE_API_KEY"]
O_API = st.secrets["OPENAI_API_KEY"]

ai_client = OpenAI(api_key=O_API)

@st.cache_resource
def get_weaviate_client():
    return weaviate.connect_to_weaviate_cloud(
        cluster_url=W_URL,
        auth_credentials=weaviate.auth.AuthApiKey(W_API),
        headers={"X-OpenAI-Api-Key": O_API}
    )

client = get_weaviate_client()

# --- HIZLI KEYWORD ROUTÄ°NG ---
def classify_query_fast(query):
    """Keyword tabanlÄ± hÄ±zlÄ± routing"""
    query_lower = query.lower()
    
    scores = {}
    for key, info in COLLECTION_MAP.items():
        score = sum(1 for keyword in info["keywords"] if keyword in query_lower)
        scores[key] = score
    
    # En yÃ¼ksek skoru bul
    if max(scores.values()) > 0:
        return max(scores, key=scores.get)
    
    return None

# --- PARALEL ARAMA ---
def search_single_collection(collection_name, query, limit):
    """Tek collection'da ara"""
    try:
        collection = client.collections.get(collection_name)
        response = collection.query.hybrid(query=query, limit=limit, alpha=0.5)
        return response.objects
    except:
        return []

def search_parallel(query, category_keys):
    """Paralel arama (daha hÄ±zlÄ±)"""
    results = []
    
    with ThreadPoolExecutor(max_workers=len(category_keys)) as executor:
        futures = {}
        
        for key in category_keys:
            info = COLLECTION_MAP[key]
            future = executor.submit(
                search_single_collection, 
                info["collection"], 
                query, 
                4 if len(category_keys) == 1 else 2
            )
            futures[future] = key
        
        for future in futures:
            key = futures[future]
            info = COLLECTION_MAP[key]
            objects = future.result()
            
            for obj in objects:
                results.append({
                    "content": obj.properties['content'],
                    "filename": obj.properties['filename'],
                    "page": obj.properties['page_number'],
                    "category": info["name"],
                    "category_key": key,
                    "emoji": info["emoji"]
                })
    
    return results

# --- TEK LLM Ã‡AÄRISI Ä°LE ROUTÄ°NG + CEVAP ---
def get_answer_with_smart_routing(query, all_results, history):
    """Tek LLM Ã§aÄŸrÄ±sÄ±nda hem kategori tespit hem cevap"""
    
    # TÃ¼m kategorilerden context hazÄ±rla
    contexts_by_category = {}
    for result in all_results:
        cat_key = result["category_key"]
        if cat_key not in contexts_by_category:
            contexts_by_category[cat_key] = []
        contexts_by_category[cat_key].append(result)
    
    # Her kategoriden context oluÅŸtur
    full_context = ""
    for cat_key, results in contexts_by_category.items():
        info = COLLECTION_MAP[cat_key]
        full_context += f"\n\n=== {info['emoji']} {info['name'].upper()} KATEGORÄ°SÄ° ===\n"
        for r in results[:2]:  # Her kategoriden max 2 belge
            full_context += f"[KAYNAK: {r['filename']} S.{r['page']}]\n{r['content'][:600]}...\n\n"
    
    # Sistem prompt'u (tek seferde hem routing hem cevap)
    system_instruction = f"""Sen kÄ±demli bir hukuk mÃ¼ÅŸavirisin. 

GÃ–REVÄ°N 2 AÅAMALI:

1. ADIM - KATEGORÄ° TESPÄ°TÄ°:
KullanÄ±cÄ±nÄ±n sorusunu analiz et ve hangi kategoriye ait olduÄŸunu belirle.
Mevcut kategoriler: {', '.join([f"{info['emoji']} {key}" for key, info in COLLECTION_MAP.items()])}

2. ADIM - CEVAP OLUÅTURMA:
BelirlediÄŸin kategorideki belgelerden yararlanarak soruyu yanÄ±tla.

KURALLAR:
- CevabÄ±n robotik olmasÄ±n, avukat gibi akÄ±cÄ± anlat
- Ã–nemli kÄ±sÄ±mlarÄ± **kalÄ±n** yaz
- Spesifik madde/kural varsa belirt
- CevabÄ±n sonunda kaynaklara atÄ±f yap
- BelirlediÄŸin kategoriyi cevabÄ±nda belirtme (otomatik gÃ¶steriyoruz)

Ã‡OK Ã–NEMLÄ°: Soruya en uygun kategorideki belgeleri kullan. DiÄŸer kategorilerdeki belgeleri gÃ¶rmezden gel."""

    # Chat history
    messages = [{"role": "system", "content": system_instruction}]
    for m in history[-2:]:  # Son 2 mesaj
        if m["role"] != "system":
            messages.append({"role": m["role"], "content": m["content"]})
    
    messages.append({
        "role": "user", 
        "content": f"{full_context}\n\nSORU: {query}"
    })
    
    # TEK LLM Ã‡AÄRISI
    return ai_client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.4,
        stream=True
    )

# --- CHAT ARAYÃœZÃœ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message.get("category_info"):
            st.markdown(message["category_info"], unsafe_allow_html=True)

if prompt := st.chat_input("Sorunuzu buraya yazÄ±n..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # ==================== 1. HIZLI ROUTÄ°NG (Keyword) ====================
        detected_category = classify_query_fast(prompt)
        
        if detected_category:
            categories_to_search = [detected_category]
            info = COLLECTION_MAP[detected_category]
            category_info_html = f'<div class="category-badge">âš¡ {info["emoji"]} {info["name"]}</div>'
        else:
            # Keyword bulamazsa tÃ¼m kategorilerde ara
            categories_to_search = list(COLLECTION_MAP.keys())
            category_info_html = '<div class="category-badge">ğŸ“š TÃ¼m Kategoriler</div>'
        
        st.markdown(category_info_html, unsafe_allow_html=True)
        
        # ==================== 2. PARALEL ARAMA ====================
        with st.spinner("ğŸ“š Belgeler taranÄ±yor..."):
            all_results = search_parallel(prompt, categories_to_search)
        
        if not all_results:
            response_text = "ÃœzgÃ¼nÃ¼m, bu konuyla ilgili belge bulunamadÄ±."
            st.warning(response_text)
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response_text,
                "category_info": category_info_html
            })
            st.stop()
        
        # ==================== 3. TEK LLM Ã‡AÄRISI (Routing + Cevap) ====================
        with st.spinner("âœï¸ YanÄ±t hazÄ±rlanÄ±yor..."):
            ai_response = get_answer_with_smart_routing(
                prompt, 
                all_results, 
                st.session_state.messages
            )
            
            # Streaming yanÄ±t
            response_placeholder = st.empty()
            full_response = ""
            
            for chunk in ai_response:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    response_placeholder.markdown(full_response + "â–Œ")
            
            response_placeholder.markdown(full_response)
            
            # ReferanslarÄ± gÃ¶ster (kullanÄ±lan kategorideki belgeler)
            used_results = [r for r in all_results if r["category_key"] == detected_category] if detected_category else all_results[:4]
            
            with st.expander("ğŸ“ KullanÄ±lan Referanslar"):
                for r in used_results:
                    st.write(f"- {r['emoji']} {r['filename']} (S. {r['page']}) - {r['category']}")

        st.session_state.messages.append({
            "role": "assistant", 
            "content": full_response,
            "category_info": category_info_html
        })
